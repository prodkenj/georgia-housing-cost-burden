---
title: "dhd"
author: "Ken Wong"
date: "2025-04-12"
output:
  pdf_document: default
  html_document: default
  word_document: default
---

# load necessary packages
```{r}
library(ggplot2)
library(dplyr)
library(car)
library(lmtest)
library(heplots)
library(nlme)
```

# load in data
```{r}
data = read.csv("/Users/wil/Downloads/CVIOGData_Feb12.csv")
head(data)
colnames(data)
str(data)
```

```{r}
plot(data$percent_renter_occupied_cost_burdened, data$MedHouseIncome)
plot(data$unemployment_rate, data$percent_renter_occupied_cost_burdened)
plot(data$percent_bachelors_higher, data$percent_renter_occupied_cost_burdened)
plot(data$isUrban, data$percent_renter_occupied_cost_burdened)
```

# convert isUrban to factor
```{r}
data$isUrban = as.factor(data$isUrban)
```

# fit model
```{r}
attach(data)
model = lm(percent_owner_occupied_cost_burdened ~ MedHouseIncome + isUrban + unemployment_rate + percent_bachelors_higher)
```

# check conditions

```{r}
hist(model$residuals)
```
# it appears that the distribution of residuals is approximately bell-shaped, indicating normality is met

```{r}
qqnorm(model$residuals)
qqline(model$residuals, col = "blue")
```
# it appears that most of the residuals appear on the linear line, indicating normality is met

```{r}
shapiro.test(model$residuals)
```
# sw test indicates we fail to have enough evidence to reject the null hypothesis and we can conclude normality is met

```{r}
plot(model, which = 1)
```
# residuals appear to be randomly scattered around the line y = 0, indicating that linearity is met

# additionaly, the variance of the residuals appears to stay constant, indicating that homoscedasticity is met

```{r}
bptest(model)
```
# Breusch-Pagan test indicates we have enough evidence to reject the null hypothesis and can conclude that heterodescasticity may be present in our model

```{r}
durbinWatsonTest(model)
```
# DW test indicates we fail to have significant evidence to reject null and can conclude that residuals' autocorrelations is 0 (i.e. independence is met)

```{r}
cor(MedHouseIncome, percent_bachelors_higher)
vif(model)
```
# None of the variance inflation factors are above 5 (with the closest one having a vif of 3.169 for percent_bachelors_higher) indicating there isn't any problem with multicollinearity present within the model

```{r}
data$log_percent_owner_occupied_cost_burdened <- log(data$percent_owner_occupied_cost_burdened)
# Now re-run the regression with the transformed variable
model_log <- lm(log_percent_owner_occupied_cost_burdened ~ MedHouseIncome + isUrban + unemployment_rate + percent_bachelors_higher, data = data)
```

```{r}
bptest(model_log)
durbinWatsonTest(model_log)
plot(model_log, which = 1)
```
# Breusch-Pagan test indicates we fail to have enough evidence to reject the null hypothesis and can conclude that heterodescasticity is not present in our model

# DW test indicates we fail to have significant evidence to reject null and can conclude that residuals' autocorrelations is 0 (i.e. independence is met)

```{r}
shapiro.test(model_log$residuals)
```
# sw test indicates we fail to have enough evidence to reject the null hypothesis and we can conclude normality is met

```{r}
qqnorm(model_log$residuals)
qqline(model_log$residuals, col="red")
```
# It appears that most of the residuals follow along on the linear line, checking off normality assumption

```{r}
hist(model_log$residuals)
```

# residuals appear to be approximately normally distributed 

```{r}
library(caret)

# Define training control
train_control <- trainControl(method = "cv", number = 10)

# Train Model 1 (original)
model_cv <- train(percent_owner_occupied_cost_burdened ~ MedHouseIncome + isUrban + unemployment_rate + percent_bachelors_higher, 
                   data = data, method = "lm", trControl = train_control)

# Train Model 2 (log-transformed)
model_log__cv <- train(log(percent_owner_occupied_cost_burdened) ~ MedHouseIncome + isUrban + unemployment_rate + percent_bachelors_higher, 
                   data = data, method = "lm", trControl = train_control)

# Compare cross-validation results
print(model_cv)
print(model_log__cv)
```
# The log-transformed model has much higher predictive power (RMSE of 0.2070227 compared to RMSE of 3.90616 due to prediction errors). It maintaisn the same level of R^2 between both models. The log transformation addresses issues with heteroscedasticity leading to better model performance.

# Backward selection for log transformation model

```{r}
full_log_model = lm(log_percent_owner_occupied_cost_burdened ~ MedHouseIncome + isUrban + unemployment_rate + percent_bachelors_higher, data = data)
summary(full_log_model)
AIC(full_log_model)
```

```{r}
log_model_minus_unemployment_rate = lm(log_percent_owner_occupied_cost_burdened ~ MedHouseIncome + isUrban + percent_bachelors_higher, data = data)
summary(log_model_minus_unemployment_rate)
AIC(log_model_minus_unemployment_rate)
```

```{r}
final_log_model = lm(log_percent_owner_occupied_cost_burdened ~ MedHouseIncome + percent_bachelors_higher, data = data)
summary(final_log_model)
AIC(final_log_model)
```

# using AIC criterion for backward selection, the model with median hh income and bachelor's or higher had the lowest AIC value

```{r}
vif(final_log_model)
```
# No multicollinearity present within the model (both vif's lower than 5)

# just to make sure, validate all model conditions
```{r}
bptest(final_log_model)
durbinWatsonTest(final_log_model)
plot(final_log_model, which = 1)
shapiro.test(final_log_model$residuals)
```
# Breusch-Pagan test indicates we fail to have enough evidence to reject the null hypothesis and can conclude that residuals are homescedastic
# Residuals appear randomly scattered around y = 0 meaning linearity is met and no patterns in residuals vs fitted plot
# DW test indicates we fail to have significant evidence to reject null and can conclude that residuals' autocorrelations is 0 (i.e. independence is met)
# Shapiro-wilks test indicates normaity

```{r}
qqnorm(final_log_model$residuals)
qqline(final_log_model$residuals, col="red")
hist(final_log_model$residuals)
```
# QQ Plot and histogram of residuals indicates normality as well

```{r}
model3 = lm(percent_renter_occupied_cost_burdened ~ isUrban + MedHouseIncome + percent_bachelors_higher + unemployment_rate, data=data)

bptest(model3)
durbinWatsonTest(model3)
shapiro.test(model3$residuals)
plot(model3, which = 1)

# Add labels (use row numbers or specific identifiers)
text(fitted(model3), residuals(model3), labels = 1:length(residuals(model3)), pos = 3, cex = 0.7)
```
# BP test indicates model fails constant variance condition
# DW test indicates that independence is met
# SW test indicates normality is met

```{r}
# Find the row corresponding to label 118
row_to_remove = which(1:length(residuals(model3)) == 118)

#Remove that row from the dataset
data_cleaned <- data[-row_to_remove, ]

# Refit the model without the removed row
model3_refitted <- lm(percent_renter_occupied_cost_burdened ~ isUrban + MedHouseIncome + percent_bachelors_higher + unemployment_rate, data = data_cleaned)

# Summary of the refitted model
summary(model3_refitted)

plot(model3_refitted, which = 1)
```

```{r}
bptest(model3_refitted)
durbinWatsonTest(model3_refitted)
shapiro.test(model3_refitted$residuals)
```

```{r}
hist(model3_refitted$residuals)
qqnorm(model3_refitted$residuals)
qqline(model3_refitted$residuals)
```
# Attempted to refit linear model by removing a residual, however, the BP test still failed

```{r}
summary(model3)
summary(model3_refitted)
```
# also, by removing the residual, unemployment rate become a non-statistically significant predictor

```{r}
data$log_percent_renter_occupied_cost_burdened <- log(data$percent_renter_occupied_cost_burdened)
# Now re-run the regression with the transformed variable
model_log2 <- lm(log_percent_renter_occupied_cost_burdened ~ MedHouseIncome + isUrban + unemployment_rate + percent_bachelors_higher, data = data)
```


```{r}
bptest(model_log2)
durbinWatsonTest(model_log2)
plot(model_log2, which = 1)

# Add labels (use row numbers or specific identifiers)
text(fitted(model_log2), residuals(model_log2), labels = 1:length(residuals(model3)), pos = 3, cex = 0.7)
```
```{r}
hist(model_log2$residuals)
```
# Distribution of residuals appears to be slightly skewed left violating normality approximation.
```{r}
qqnorm(model_log2$residuals)
qqline(model_log2$residuals)
```
# QQ-plot indicates independence is met
```{r}
shapiro.test(model_log2$residuals)
```
# SW test confirms normality condition is violated by the log-transformation for the renter-occupied household's model

# BP test also strongly confirms instance of heterodescasticity being present within residuals

```{r}
# Find the row corresponding to label 118
row_to_remove2 = which(1:length(residuals(model_log2)) == 118)

#Remove that row from the dataset
data_cleaned2 <- data[-row_to_remove2, ]

# Refit the model without the removed row
model_log2_refitted <- lm(percent_renter_occupied_cost_burdened ~ isUrban + MedHouseIncome + percent_bachelors_higher + unemployment_rate, data = data_cleaned2)

# Summary of the refitted model
summary(model_log2_refitted)

plot(model_log2_refitted, which = 1)
```
# Attempted to refit the model by removing a residual, however, unemployment rate become a non-statistically significant predictor


```{r}
bptest(model_log2_refitted)
durbinWatsonTest(model_log2_refitted)
shapiro.test(model_log2_refitted$residuals)
```

```{r}
hist(model_log2_refitted$residuals)
```

```{r}
qqnorm(model_log2_refitted$residuals)
qqline(model_log2_refitted$residuals)
```
# Solved issue of normality being violated, but there is still non-constant variance present in model

```{r}
summary(model_log2)
summary(model_log2_refitted)
```

```{r}
 #Fit WLS model using weights = 1 / residual variance
wls_model3 <- gls(percent_renter_occupied_cost_burdened ~ isUrban + MedHouseIncome + percent_bachelors_higher + unemployment_rate, data = data, weights = varFixed(~ MedHouseIncome))

# Check residuals
plot(wls_model3, which = 1)
```
# Residuals appear to be stabalized using wls method

```{r}
data$isUrban <- as.numeric(data$isUrban)  # Converts factor to numeric (1, 2, etc.)
residuals_squared <- residuals(wls_model3)^2
cor(data[, c("MedHouseIncome", "isUrban", "percent_bachelors_higher", "unemployment_rate")], residuals_squared, use = "complete.obs")
```
# It appears that isUrban would be the best predictor to weight on based on correlation value (absolute value being the highest), since the highest correlation value is indicating the variable that residual variance is highly dependant on (hence why ideally we will weight on isUrban)

```{r}
hist(wls_model3$residuals)
```

```{r}
shapiro.test(wls_model3$residuals)
```

```{r}
qqnorm(wls_model3$residuals)
qqline(wls_model3$residuals)
```

```{r}
dwtest(residuals(wls_model3) ~ 1)
```

```{r}
summary(wls_model3)
```

```{r}
wls_model3_urban_wt <- gls(percent_renter_occupied_cost_burdened ~ isUrban + MedHouseIncome + percent_bachelors_higher + unemployment_rate, 
                 data = data, 
                 weights = varIdent(form = ~ 1 | isUrban))
```

```{r}
library(lmtest)

# Extract residuals and fitted values
residuals_squared <- residuals(wls_model3_urban_wt, type = "pearson")^2
fitted_values <- fitted(wls_model3_urban_wt)

# Fit auxiliary regression
bp_model <- lm(residuals_squared ~ fitted_values, data = data)

# Perform Breusch-Pagan test
bptest(bp_model)
```

```{r}
# Extract Pearson residuals and fitted values
residuals_squared1 <- residuals(wls_model3, type = "pearson")^2
fitted_values1 <- fitted(wls_model3)

# Fit auxiliary regression
bp_model1 <- lm(residuals_squared1 ~ fitted_values1, data = data)

# Perform Breusch-Pagan test
bptest(bp_model1)
```

```{r}
wls_model3_medhouseinc <- gls(percent_renter_occupied_cost_burdened ~ isUrban + MedHouseIncome + percent_bachelors_higher + unemployment_rate, 
                 data = data, 
                 weights = varPower(form = ~ MedHouseIncome))
```

```{r}
# Extract Pearson residuals and fitted values
residuals_squared2 <- residuals(wls_model3_medhouseinc, type = "pearson")^2
fitted_values2 <- fitted(wls_model3_medhouseinc)

# Fit auxiliary regression
bp_model2 <- lm(residuals_squared2 ~ fitted_values2, data = data)

# Perform Breusch-Pagan test
bptest(bp_model2)
```

```{r}
summary(wls_model3)
summary(wls_model3_medhouseinc)
summary(wls_model3_urban_wt)
```

```{r}
final_wls_model = wls_model3_urban_wt
summary(final_wls_model)
```

```{r}
# Check residuals
plot(final_wls_model, which = 1)
```

```{r}

# Define training control
train_control <- trainControl(method = "cv", number = 10)

# OLS model
model_ols <- train(percent_renter_occupied_cost_burdened ~ MedHouseIncome + isUrban + unemployment_rate + percent_bachelors_higher, 
                   data = data, method = "lm", trControl = train_control)

# Log-transformed model
model_log <- train(log(percent_renter_occupied_cost_burdened) ~ MedHouseIncome + isUrban + unemployment_rate + percent_bachelors_higher, 
                   data = data, method = "lm", trControl = train_control)

# Compare results
print(model_ols)
print(model_log)
```

# Model3 i.e. mlr for renter-occupied households is best based on R-squared, however, the log model is better based on cross-validation results with a much lower RMSE. But, both models fail on heteroscedasticy so the final wls model is the best fit if we base the decision on heteroscedasticity.

```{r}
summary(final_wls_model)
wls_model3_urban_wt_no_unemployment_rate <- gls(percent_renter_occupied_cost_burdened ~ isUrban + MedHouseIncome + percent_bachelors_higher,
                 data = data, 
                 weights = varIdent(form = ~ 1 | isUrban))
summary(wls_model3_urban_wt_no_unemployment_rate)
```
# Used backward selection to remove unemployment rate due to insignificant p-value and resulted in BIC decrease from 1151.607 to 1148.877

# Ultimately, used wls model weighting on isUrban, since the bpTest indicated it had the least significant p-value (i.e. most evidence to reject that heterodescasticity was present in the model)
